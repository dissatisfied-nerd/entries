{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d873f7",
   "metadata": {},
   "source": [
    "# Излечение, преобразование, загрузка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc3b8e",
   "metadata": {},
   "source": [
    "## Импортируем необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04c9abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c3a57",
   "metadata": {},
   "source": [
    "## Настраиваем подключение к БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac81e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"entries_user\"\n",
    "password = \"entries_password\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"entries_db\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3261e",
   "metadata": {},
   "source": [
    "## intervals_tgt\n",
    "\n",
    "Основа обработки - итерация по датам (ГГГГ-ММ-ДД) для каждого вхождения full_name, рассмотрение каждой записи, формирование из наиболее близких \"Вход\" и \"Выход\" интервала. Рассмотрим обработку аномалий:\n",
    "1. Ошибки системы - из пар записей с одинаковыми статусами и временной разницей менее минуты выбираем более позднюю, другую отбрасываем.\n",
    "2. Экстренный вход - если выход был произведён в обход системы, то повторный вход не рассматриваем как действительное начало интервала.\n",
    "3. Ночные выходы - если последней по времени записью для указанной даты является вход, то ищем самый ранний выход в следующем дне. По условию сотрудник не может пропасть или выйти, минуя систему, и не вернуться, учтённый выход на следующий день помечаем, чтобы избежать его повторного учёта.\n",
    "4. Перерыв на обед - если для указанной даты несколько пар входов и выходов или пара входов и выходов и вход, то учитываем несколько интервалов для одной даты.\n",
    "5. Конец учётного периода - если сотрудник остался в ночь, совпадающую с окончанием отчётного периода, то его интервал закрывается датой и временем окончания отчётного периода.\n",
    "\n",
    "1. Группируем события по full_name\n",
    "2. Сортируем каждую группу по дате по возрастанию.\n",
    "3. Фильтруем данные по парам:\n",
    "    - Убираем дубликаты записей (один и тот же статус, время отличается меньше чем на минуту)\n",
    "    - Убираем записи \"Доступ запрещён\", когда ожидался \"Вход\".\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b10586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-04-17 19:22:50 2006-04-18 09:00:00\n",
      "2006-04-19 19:30:45 2006-04-20 10:18:41\n",
      "2006-04-20 19:27:32 2006-04-21 10:21:39\n",
      "2006-05-11 18:09:40 2006-05-12 09:29:39\n",
      "2006-06-29 18:08:43 2006-06-30 09:05:14\n",
      "2006-05-09 18:14:15 2006-05-10 08:27:38\n",
      "2006-06-06 18:21:03 2006-06-07 08:16:16\n",
      "2006-06-07 17:18:05 2006-06-08 10:04:15\n",
      "2006-05-22 19:10:30 2006-05-23 10:00:32\n",
      "2006-04-05 17:21:15 2006-04-06 08:20:54\n",
      "2006-05-02 17:20:56 2006-05-03 10:24:37\n",
      "2006-05-15 19:04:07 2006-05-16 09:03:54\n",
      "2006-06-23 18:18:12 2006-06-26 09:25:44\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM entries_src ORDER BY full_name, event_dt\", engine)\n",
    "df['event_dt'] = pd.to_datetime(df['event_dt'])\n",
    "\n",
    "report_period_end = df['event_dt'].max().normalize() + pd.Timedelta(hours=23, minutes=59, seconds=59)\n",
    "\n",
    "results = []\n",
    "used_indexes = set()\n",
    "\n",
    "for name, group in df.groupby('full_name'):\n",
    "    sorted_group = group.sort_values(by=\"event_dt\")\n",
    "    rows = list(sorted_group.itertuples(index=True))\n",
    "\n",
    "    to_drop = []\n",
    "\n",
    "    for row_i, row_j in zip(rows, rows[1:]):\n",
    "        if (row_i.status == row_j.status) and (row_j.event_dt - row_i.event_dt < pd.Timedelta(seconds=60)):\n",
    "            to_drop.append(row_i.Index)\n",
    "\n",
    "        if (row_i.status == 'Доступ запрещён') and (row_j.status == 'Вход'):\n",
    "            to_drop.append(row_i.Index)\n",
    "\n",
    "    sorted_group.drop(to_drop, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc7220",
   "metadata": {},
   "source": [
    "## workdays_tgt\n",
    "\n",
    "Для каждого сотрудника рассматриваем все возможные даты (ГГГГ-ММ-ДД), для каждой даты в качестве начала рабочего дня считается наименьшее значение начала интервала, а в качестве окончания рабочего дня считается значение окончания интервала, соответствующее наибольшему значению начала интервала, соответствующей рассматриваемой даты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a33d8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['full_name', 'report_dt', 'enter_dt', 'exit_dt'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m workdays_df = pd.DataFrame(results)\n\u001b[32m     27\u001b[39m workdays_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] = workdays_df.index + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mworkdays_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfull_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreport_dt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menter_dt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexit_dt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.to_sql(\n\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mworkdays_tgt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m     engine,\n\u001b[32m     32\u001b[39m     if_exists=\u001b[33m'\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     33\u001b[39m     index=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prog/entries/venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prog/entries/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prog/entries/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['full_name', 'report_dt', 'enter_dt', 'exit_dt'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM intervals_tgt ORDER BY full_name, enter_dt\", engine)\n",
    "df['enter_dt'] = pd.to_datetime(df['enter_dt'])\n",
    "df['exit_dt'] = pd.to_datetime(df['exit_dt'])\n",
    "\n",
    "df['report_dt'] = df['enter_dt'].dt.date\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, group in df.groupby('full_name'):\n",
    "    group = group.sort_values('enter_dt').reset_index(drop=True)\n",
    "    \n",
    "    grouped_by_date = group.groupby('report_dt')\n",
    "\n",
    "    for date, day_group in grouped_by_date:\n",
    "        enter_dt = day_group['enter_dt'].min()\n",
    "        exit_dt = day_group[day_group['enter_dt'] == day_group['enter_dt'].max()]['exit_dt'].iloc[0]\n",
    "\n",
    "        results.append({\n",
    "            'full_name': name,\n",
    "            'report_dt': date,\n",
    "            'enter_dt': enter_dt,\n",
    "            'exit_dt': exit_dt\n",
    "        })\n",
    "\n",
    "workdays_df = pd.DataFrame(results)\n",
    "\n",
    "workdays_df['id'] = workdays_df.index + 1\n",
    "\n",
    "workdays_df[['id', 'full_name', 'report_dt', 'enter_dt', 'exit_dt']].to_sql(\n",
    "    'workdays_tgt',\n",
    "    engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f000f1",
   "metadata": {},
   "source": [
    "## aggregated_info_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_aggregated_info = \"\"\"\n",
    "INSERT INTO aggregated_info_tgt (\n",
    "    full_name,\n",
    "    month,\n",
    "    workdays_count,\n",
    "    on_time_count,\n",
    "    late_0_15,\n",
    "    late_15_30,\n",
    "    late_30_60,\n",
    "    late_60_plus,\n",
    "    full_day_count,\n",
    "    short_day_count,\n",
    "    avg_worktime\n",
    ")\n",
    "SELECT\n",
    "    full_name,\n",
    "    TO_CHAR(report_dt, 'YYYY-MM') AS month,\n",
    "    COUNT(*) AS workdays_count,\n",
    "    COUNT(*) FILTER (WHERE enter_dt::time <= TIME '09:00:00') AS on_time_count,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE enter_dt::time > TIME '09:00:00'\n",
    "          AND EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 <= 15\n",
    "    ) AS late_0_15,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 > 15\n",
    "          AND EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 <= 30\n",
    "    ) AS late_15_30,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 > 30\n",
    "          AND EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 <= 60\n",
    "    ) AS late_30_60,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE EXTRACT(EPOCH FROM (enter_dt::time - TIME '09:00:00')) / 60 > 60\n",
    "    ) AS late_60_plus,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE EXTRACT(EPOCH FROM (exit_dt - enter_dt)) / 3600 >= 9\n",
    "    ) AS full_day_count,\n",
    "    COUNT(*) FILTER (\n",
    "        WHERE EXTRACT(EPOCH FROM (exit_dt - enter_dt)) / 3600 < 9\n",
    "    ) AS short_day_count,\n",
    "    ROUND(AVG(EXTRACT(EPOCH FROM (exit_dt - enter_dt)) / 3600), 2) AS avg_worktime\n",
    "FROM workdays_tgt\n",
    "GROUP BY full_name, TO_CHAR(report_dt, 'YYYY-MM')\n",
    "ORDER BY full_name, TO_CHAR(report_dt, 'YYYY-MM');\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        conn.execute(text(query_aggregated_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec11911",
   "metadata": {},
   "source": [
    "## Эскпортируем полученные таблицы в .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06de923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица entries_src сохранена в файл data/target/entries_src.csv\n",
      "Таблица intervals_tgt сохранена в файл data/target/intervals_tgt.csv\n",
      "Таблица aggregated_info_tgt сохранена в файл data/target/aggregated_info_tgt.csv\n"
     ]
    }
   ],
   "source": [
    "tables = ['entries_src', 'intervals_tgt', 'aggregated_info_tgt']\n",
    "\n",
    "for table in tables:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table}\", engine)\n",
    "    csv_filename = f\"data/target/{table}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Таблица {table} сохранена в файл {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
